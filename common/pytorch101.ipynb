{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Fundamentals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pytorch\n",
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "# Check for Cuda based CPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7), 0, torch.Size([]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar - Scalar has no dimensions\n",
    "scalar = torch.tensor(7)\n",
    "scalar, scalar.ndim, scalar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, int, array(7))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Genting tensor back as python int\n",
    "scalar.item(), type(scalar.item()), scalar.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2, 2]), 1, torch.Size([2]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector - Vectors has single dimension\n",
    "vector = torch.tensor([2, 2])\n",
    "vector, vector.ndim, vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 2 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Vectore or any high dimensinal representation can't be converted into basic python datatypes\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mvector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 2 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "# Vectore or any high dimensinal representation can't be converted into basic python datatypes\n",
    "vector.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 2]), numpy.ndarray)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Higher dimension tensors can be converted into numpy arrays\n",
    "vector.numpy(), type(vector.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2],\n",
       "         [4, 5]]),\n",
       " 2,\n",
       " torch.Size([2, 2]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix - matrix has 3 dimensions\n",
    "\n",
    "MATRIX = torch.tensor([[1, 2], [4, 5]])\n",
    "\n",
    "MATRIX, MATRIX.ndim, MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the matrix into numpy array\n",
    "MATRIX.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [6, 7, 8]]]),\n",
       " 3,\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor - Any representation which is higher than 2 dimensions are called tensor\n",
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                        [4,5,6],\n",
    "                        [6,7,8]]])\n",
    "\n",
    "TENSOR, TENSOR.ndim, TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [2, 3, 4],\n",
       "          [4, 5, 6]],\n",
       " \n",
       "         [[2, 3, 4],\n",
       "          [3, 4, 5],\n",
       "          [4, 5, 6]],\n",
       " \n",
       "         [[5, 6, 7],\n",
       "          [6, 7, 8],\n",
       "          [7, 8, 9]]]),\n",
       " 3,\n",
       " torch.Size([3, 3, 3]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a high dimensional tensor\n",
    "TENSOR1 = torch.tensor([\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [2,3,4],\n",
    "        [4,5,6]\n",
    "    ],\n",
    "    [\n",
    "        [2,3,4],\n",
    "        [3,4,5],\n",
    "        [4,5,6]\n",
    "    ],\n",
    "    [\n",
    "        [5,6,7],\n",
    "        [6,7,8],\n",
    "        [7,8,9]\n",
    "    ]\n",
    "])\n",
    "\n",
    "TENSOR1, TENSOR1.ndim, TENSOR1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 3],\n",
       "        [2, 3, 4],\n",
       "        [4, 5, 6]],\n",
       "\n",
       "       [[2, 3, 4],\n",
       "        [3, 4, 5],\n",
       "        [4, 5, 6]],\n",
       "\n",
       "       [[5, 6, 7],\n",
       "        [6, 7, 8],\n",
       "        [7, 8, 9]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0823, 0.9386, 0.2882],\n",
       "         [0.5603, 0.2029, 0.8637],\n",
       "         [0.8846, 0.4053, 0.4222]]),\n",
       " 2,\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating random tensors\n",
    "\n",
    "RANDOM_TENSOR = torch.rand(3,3)\n",
    "RANDOM_TENSOR, RANDOM_TENSOR.ndim, RANDOM_TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[9.8578e-01, 8.1515e-04, 2.3163e-01],\n",
       "          [5.7306e-01, 5.3345e-02, 5.6700e-01]],\n",
       " \n",
       "         [[1.1941e-01, 3.8047e-02, 5.2982e-01],\n",
       "          [5.4047e-01, 6.2658e-03, 1.7898e-01]],\n",
       " \n",
       "         [[3.0821e-01, 9.8298e-01, 2.5448e-01],\n",
       "          [7.1243e-01, 8.6101e-01, 2.3488e-01]]]),\n",
       " 3,\n",
       " torch.Size([3, 2, 3]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_TENSOR1 = torch.rand(3,2,3)\n",
    "RANDOM_TENSOR1, RANDOM_TENSOR1.ndim, RANDOM_TENSOR1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.1646],\n",
       "          [0.6202],\n",
       "          [0.5110],\n",
       "          [0.7288]],\n",
       " \n",
       "         [[0.1149],\n",
       "          [0.5530],\n",
       "          [0.6424],\n",
       "          [0.5867]],\n",
       " \n",
       "         [[0.9275],\n",
       "          [0.8683],\n",
       "          [0.4266],\n",
       "          [0.0999]]]),\n",
       " 3,\n",
       " torch.Size([3, 4, 1]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_TENSOR2 = torch.rand(3,4,1)\n",
    "RANDOM_TENSOR2, RANDOM_TENSOR2.ndim, RANDOM_TENSOR2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.4908, 0.1631, 0.6877],\n",
       "          [0.1832, 0.2233, 0.3894],\n",
       "          [0.0593, 0.2149, 0.5402],\n",
       "          ...,\n",
       "          [0.2437, 0.1051, 0.8612],\n",
       "          [0.3675, 0.9235, 0.3517],\n",
       "          [0.4929, 0.3742, 0.4066]],\n",
       " \n",
       "         [[0.5611, 0.1014, 0.7051],\n",
       "          [0.2625, 0.8378, 0.6856],\n",
       "          [0.6474, 0.5882, 0.3454],\n",
       "          ...,\n",
       "          [0.0592, 0.6731, 0.5259],\n",
       "          [0.2657, 0.7419, 0.8685],\n",
       "          [0.0282, 0.8033, 0.6557]],\n",
       " \n",
       "         [[0.5855, 0.8774, 0.1039],\n",
       "          [0.8938, 0.4146, 0.3714],\n",
       "          [0.2301, 0.1166, 0.9523],\n",
       "          ...,\n",
       "          [0.8816, 0.0409, 0.3102],\n",
       "          [0.7642, 0.1526, 0.8095],\n",
       "          [0.4319, 0.9481, 0.8615]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.0800, 0.9441, 0.1036],\n",
       "          [0.7439, 0.1061, 0.4440],\n",
       "          [0.5982, 0.2064, 0.9190],\n",
       "          ...,\n",
       "          [0.9902, 0.7669, 0.2473],\n",
       "          [0.9070, 0.4428, 0.5059],\n",
       "          [0.8208, 0.6711, 0.5792]],\n",
       " \n",
       "         [[0.9453, 0.5077, 0.9160],\n",
       "          [0.7739, 0.1994, 0.3842],\n",
       "          [0.8807, 0.4632, 0.5520],\n",
       "          ...,\n",
       "          [0.9321, 0.1806, 0.4884],\n",
       "          [0.9880, 0.7811, 0.2759],\n",
       "          [0.4353, 0.0044, 0.3474]],\n",
       " \n",
       "         [[0.5207, 0.8706, 0.3082],\n",
       "          [0.6322, 0.4130, 0.7638],\n",
       "          [0.6174, 0.6522, 0.1298],\n",
       "          ...,\n",
       "          [0.2550, 0.3234, 0.6857],\n",
       "          [0.9923, 0.4146, 0.7160],\n",
       "          [0.6090, 0.2603, 0.2868]]]),\n",
       " 3,\n",
       " torch.Size([128, 128, 3]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usually 3 dimensional are used to represent the image - height, width, colour channels\n",
    "IMAGE_TENSOR = torch.rand(128,128,3) # There are 3 colour channels RGB\n",
    "IMAGE_TENSOR, IMAGE_TENSOR.ndim, IMAGE_TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0971, 0.1804, 0.9167,  ..., 0.7599, 0.6302, 0.4564],\n",
       "          [0.1572, 0.8615, 0.9748,  ..., 0.9499, 0.0570, 0.1486],\n",
       "          [0.4153, 0.6198, 0.9386,  ..., 0.6616, 0.2318, 0.7932],\n",
       "          ...,\n",
       "          [0.6448, 0.9474, 0.5037,  ..., 0.5918, 0.4951, 0.2397],\n",
       "          [0.8033, 0.5629, 0.0896,  ..., 0.5762, 0.0442, 0.6353],\n",
       "          [0.4749, 0.9245, 0.8320,  ..., 0.3005, 0.5808, 0.4453]],\n",
       " \n",
       "         [[0.5025, 0.0504, 0.6066,  ..., 0.7590, 0.9262, 0.8576],\n",
       "          [0.6012, 0.0135, 0.5251,  ..., 0.9850, 0.1128, 0.9943],\n",
       "          [0.1797, 0.6717, 0.4255,  ..., 0.2188, 0.6588, 0.4844],\n",
       "          ...,\n",
       "          [0.2162, 0.1267, 0.0266,  ..., 0.5170, 0.6924, 0.2608],\n",
       "          [0.1824, 0.5920, 0.0161,  ..., 0.0020, 0.4412, 0.9079],\n",
       "          [0.4803, 0.4572, 0.6586,  ..., 0.7952, 0.6895, 0.5079]],\n",
       " \n",
       "         [[0.8091, 0.2805, 0.2604,  ..., 0.7331, 0.6482, 0.0912],\n",
       "          [0.5453, 0.8000, 0.1026,  ..., 0.3908, 0.8612, 0.2298],\n",
       "          [0.4946, 0.8606, 0.2847,  ..., 0.6385, 0.8210, 0.2887],\n",
       "          ...,\n",
       "          [0.8558, 0.0025, 0.2669,  ..., 0.3115, 0.6118, 0.7864],\n",
       "          [0.6593, 0.1730, 0.2882,  ..., 0.7530, 0.7431, 0.5796],\n",
       "          [0.9648, 0.9659, 0.7780,  ..., 0.3444, 0.7167, 0.5599]]]),\n",
       " 3,\n",
       " torch.Size([3, 128, 128]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sometimes the colour channels are represented in first dimension - colour channels, height, width\n",
    "IMAGE_TENSOR1 = torch.rand(3, 128, 128)\n",
    "IMAGE_TENSOR1, IMAGE_TENSOR1.ndim, IMAGE_TENSOR1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " 2,\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensors for zeros and ones\n",
    "# This shall be used to create mask\n",
    "ZERO_TENSOR = torch.zeros(3,3)\n",
    "ZERO_TENSOR, ZERO_TENSOR.ndim, ZERO_TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]),\n",
       " 2,\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ONE_TENSOR = torch.ones(3,3)\n",
    "ONE_TENSOR, ONE_TENSOR.ndim, ONE_TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By default the tensors are created as float32\n",
    "ONE_TENSOR.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8140, 0.9263, 0.3369],\n",
       "         [0.7725, 0.4858, 0.7134],\n",
       "         [0.9590, 0.5430, 0.0967]], dtype=torch.float16),\n",
       " torch.float16)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We could create tensors with different datatypes\n",
    "RANDOM_TENSOR3 = torch.rand(3,3, dtype=torch.float16)\n",
    "RANDOM_TENSOR3, RANDOM_TENSOR3.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1680, 0.3086],\n",
       "         [0.5273, 0.7539]], dtype=torch.bfloat16),\n",
       " torch.bfloat16)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating rand tensors with type bfloat16 - binary float 16\n",
    "# This is a newer datatype which shall use 16 bits for each element in the tensor but supports higher precision due to it's bits distribution\n",
    "RANDOM_TENSOR4 = torch.rand(2,2, dtype=torch.bfloat16)\n",
    "RANDOM_TENSOR4, RANDOM_TENSOR4.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8]), 1, torch.Size([9]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a range of tensors\n",
    "RANGE_TENSOR = torch.arange(0,9)\n",
    "RANGE_TENSOR, RANGE_TENSOR.ndim, RANGE_TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  1, 101, 201, 301, 401, 501, 601, 701, 801, 901]), torch.int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a range of tensor with steps\n",
    "RANGE_TENSOR1 = torch.arange(start=1, end=1000, step=100)\n",
    "RANGE_TENSOR1, RANGE_TENSOR1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), torch.int64, 1, torch.Size([10]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensors like - creating tensors like different tensors\n",
    "LIKE_TENSOR = torch.ones_like(RANGE_TENSOR1)\n",
    "LIKE_TENSOR, LIKE_TENSOR.dtype, LIKE_TENSOR.ndim, LIKE_TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), torch.int64, torch.Size([10]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarly we could create like tensors of zeros \n",
    "LIKE_TENSOR1 = torch.zeros_like(RANGE_TENSOR1)\n",
    "LIKE_TENSOR1, LIKE_TENSOR1.dtype, LIKE_TENSOR1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8984, 0.2852, 0.5391],\n",
       "         [0.9883, 0.2891, 0.7422],\n",
       "         [0.8750, 0.0977, 0.4570]], dtype=torch.bfloat16),\n",
       " torch.bfloat16,\n",
       " device(type='cpu'))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important args while creating tensors\n",
    "# dtype - defines the datatype of the tensor\n",
    "# device - defines the device the tensor need to be created - could be cuda if cuda based GPU is available\n",
    "# requires_grad - this will define that the gradiants need to be calculated during the processing - this will be helpful in training stage\n",
    "RANDOM_TENSOR5 = torch.rand(3,3, dtype=torch.bfloat16, device='cpu', requires_grad=False)\n",
    "RANDOM_TENSOR5, RANDOM_TENSOR5.dtype, RANDOM_TENSOR5.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9922, 0.6406],\n",
       "         [0.3555, 0.5781]], dtype=torch.bfloat16),\n",
       " torch.bfloat16,\n",
       " device(type='cpu'))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_TENSOR6 = torch.rand(2,2, dtype=torch.bfloat16, device=None, requires_grad=False)\n",
    "RANDOM_TENSOR6, RANDOM_TENSOR6.dtype, RANDOM_TENSOR6.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
