{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InPDxP-7xQDn",
        "outputId": "d194b2af-d0c0-422e-c545-ca43bcddeb30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ai_core import QwenLocal, GemmaLocal, LlamaLocal, PhiLocal, RolePlay\n",
        "from rich.console import Console\n",
        "from rich import print as rprint\n",
        "from pprint import pprint\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "import os\n",
        "\n",
        "from ai_core.test import documents, tools_schema, react_prompt, new_react_prompt, messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yr9IDZkx-Dp"
      },
      "source": [
        "# General"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "D3OAH82Sx6xJ"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = \"You're a sarcastic AI assistant with Dark Humour\"\n",
        "USER_PROMPT1 = \"Hi How are you Doing?\"\n",
        "USER_PROMPT2 = \"What can you do?\"\n",
        "RAG_PROMPT = \"What are the key principles of Quantum Computing?\"\n",
        "TOOL_PROMPT = \"Can you retrieve the details for the user with the ID 7890, who has black as their special request?\"\n",
        "\n",
        "CHAT_PROMPT1 = \"Hi, My Name is Venkat, Please address me with my name always\"\n",
        "CHAT_PROMPT2 = \"Can you tell me some different names you know with my name in it?\"\n",
        "CHAT_PROMPT3 = \"I hope you remember my name, can you tell my name?\"\n",
        "\n",
        "role_play_configs = [\n",
        "    RolePlay(role=\"Deepak\", persona=\"A meticulous and strategic manager who ensures projects run smoothly. He focuses on business goals, deadlines, and resource allocation.\"),\n",
        "    RolePlay(role=\"Venkat\", persona=\"A skilled developer with deep technical expertise. He prioritizes efficiency, clean code, and optimal system design.\"),\n",
        "    RolePlay(role=\"John\", persona=\"A detail-oriented tester who thrives on finding edge cases and ensuring product stability.\"),\n",
        "    RolePlay(role=\"Britney\", persona=\"A business client who values user experience and is focused on solving real-world problems for customers.\")\n",
        "]\n",
        "\n",
        "available_roles = [role.role for role in role_play_configs]\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"Deepak\", \"content\": \"Team, we have a new feature request from Britney. Let's discuss the feasibility and timeline.\"},\n",
        "\n",
        "    {\"role\": \"Britney\", \"content\": \"Yes, I want to add an **advanced search feature** to our platform. Users are struggling to find relevant items quickly.\"},\n",
        "\n",
        "    {\"role\": \"Venkat\", \"content\": \"That sounds interesting. Britney, do you have any specific filters in mind? Should it be keyword-based, category-based, or something more advanced like AI-powered recommendations?\"},\n",
        "\n",
        "    {\"role\": \"Britney\", \"content\": \"A combination of both! Users should be able to search by keywords, but I also want **smart suggestions** based on their browsing history.\"},\n",
        "\n",
        "    {\"role\": \"John\", \"content\": \"From a testing perspective, we need to ensure the search results are accurate. Venkat, how complex will the AI recommendations be? We might need test cases for various user behaviors.\"},\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "model_outputs = {\n",
        "    'Qwen' : {\n",
        "        'model_name': 'Qwen',\n",
        "        'in_out_pairs': []\n",
        "    },\n",
        "    'Gemma' : {\n",
        "        'model_name': 'Gemma',\n",
        "        'in_out_pairs': []\n",
        "    },\n",
        "    'Llama' : {\n",
        "        'model_name': 'Llama',\n",
        "        'in_out_pairs': []\n",
        "    },\n",
        "    'Phi': {\n",
        "        'model_name': 'Phi',\n",
        "        'in_out_pairs': []\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDY7iFts0GMR"
      },
      "source": [
        "# Qwen Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "c3b20d4b71284906bfdd4a21dd991769",
            "ce2792c815de4df88e486d31331b8116",
            "2802d92d8e1e44d1ab95b126758ac827",
            "96c5cd4030274b81930c500c27356c6f",
            "e4c3f90077164f70bb343e7ad58b993c",
            "c85eee084c664c079defed4545ca6305",
            "c9437f91800b4b36a419aebc22fff2fa",
            "4d03c13c4e9a4dbc8b6ab2ead8662e0d",
            "0b202f2bd609408bacc8ae0f1cabc411",
            "4f321409dfe24d2b94ac112baf6eeb3d",
            "8168afcee2554b9a9e60f3a5bc6e291e"
          ]
        },
        "id": "XlH79T3ox_Bq",
        "outputId": "2367b4f0-5db1-42f7-a7c2-524c5ab1eae4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Qwen model loading...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3b20d4b71284906bfdd4a21dd991769",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**************************************************\n"
          ]
        }
      ],
      "source": [
        "# Load Qwen and Gemma and llama mini models\n",
        "print('Qwen model loading...')\n",
        "qwen_model = QwenLocal('Qwen/Qwen2.5-3B-Instruct', token_limit=256)\n",
        "qwen_messages = messages.copy()\n",
        "print('*'*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yz9Kbbfey29V",
        "outputId": "fc9523bb-1bfb-4a61-ea79-8da9628a6759"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generating response for  Deepak\n",
            "Generating response for prompt: \n",
            "\n",
            " [\"\\n<|im_start|>system\\nYou are in a group chatt. Your assigned role is Deepak. Always respond in the Deepak persona conceisly.\\n\\nHere are the personas for each role:\\n\\n- Deepak: A meticulous and strategic manager who ensures projects run smoothly. He focuses on business goals, deadlines, and resource allocation.\\n\\n- Venkat: A skilled developer with deep technical expertise. He prioritizes efficiency, clean code, and optimal system design.\\n\\n- John: A detail-oriented tester who thrives on finding edge cases and ensuring product stability.\\n\\n- Britney: A business client who values user experience and is focused on solving real-world problems for customers.\\n\\n<|im_end|>\\n<|im_start|>assistant\\nDeepak: Team, we have a new feature request from Britney. Let's discuss the feasibility and timeline.<|im_end|>\\n<|im_start|>user\\nBritney: Yes, I want to add an **advanced search feature** to our platform. Users are struggling to find relevant items quickly.<|im_end|>\\n<|im_start|>user\\nVenkat: That sounds interesting. Britney, do you have any specific filters in mind? Should it be keyword-based, category-based, or something more advanced like AI-powered recommendations?<|im_end|>\\n<|im_start|>user\\nBritney: A combination of both! Users should be able to search by keywords, but I also want **smart suggestions** based on their browsing history.<|im_end|>\\n<|im_start|>user\\nJohn: From a testing perspective, we need to ensure the search results are accurate. Venkat, how complex will the AI recommendations be? We might need test cases for various user behaviors.<|im_end|>\\n<|im_start|>assistant\\n\"] \n",
            "\n",
            "\n",
            "Generated response:  ['Deepak: Excellent points, everyone. We can allocate resources for this feature, but let’s make sure it aligns with our current priorities and budget constraints. We’ll need to review the development timeline and prioritize testing phases accordingly. Venkat, could you provide us with an estimate for the complexity and potential challenges involved in implementing smart suggestions and AI recommendations? John, please outline the necessary test cases to cover all scenarios.<|im_end|>']\n",
            " Excellent points, everyone. We can allocate resources for this feature, but let’s make sure it aligns with our current priorities and budget constraints. We’ll need to review the development timeline and prioritize testing phases accordingly. Venkat, could you provide us with an estimate for the complexity and potential challenges involved in implementing smart suggestions and AI recommendations? John, please outline the necessary test cases to cover all scenarios.\n",
            "generating response for  Venkat\n",
            "Generating response for prompt: \n",
            "\n",
            " [\"\\n<|im_start|>system\\nYou are in a group chatt. Your assigned role is Venkat. Always respond in the Venkat persona conceisly.\\n\\nHere are the personas for each role:\\n\\n- Deepak: A meticulous and strategic manager who ensures projects run smoothly. He focuses on business goals, deadlines, and resource allocation.\\n\\n- Venkat: A skilled developer with deep technical expertise. He prioritizes efficiency, clean code, and optimal system design.\\n\\n- John: A detail-oriented tester who thrives on finding edge cases and ensuring product stability.\\n\\n- Britney: A business client who values user experience and is focused on solving real-world problems for customers.\\n\\n<|im_end|>\\n<|im_start|>user\\nDeepak: Team, we have a new feature request from Britney. Let's discuss the feasibility and timeline.<|im_end|>\\n<|im_start|>user\\nBritney: Yes, I want to add an **advanced search feature** to our platform. Users are struggling to find relevant items quickly.<|im_end|>\\n<|im_start|>assistant\\nVenkat: That sounds interesting. Britney, do you have any specific filters in mind? Should it be keyword-based, category-based, or something more advanced like AI-powered recommendations?<|im_end|>\\n<|im_start|>user\\nBritney: A combination of both! Users should be able to search by keywords, but I also want **smart suggestions** based on their browsing history.<|im_end|>\\n<|im_start|>user\\nJohn: From a testing perspective, we need to ensure the search results are accurate. Venkat, how complex will the AI recommendations be? We might need test cases for various user behaviors.<|im_end|>\\n<|im_start|>user\\nDeepak:  Excellent points, everyone. We can allocate resources for this feature, but let’s make sure it aligns with our current priorities and budget constraints. We’ll need to review the development timeline and prioritize testing phases accordingly. Venkat, could you provide us with an estimate for the complexity and potential challenges involved in implementing smart suggestions and AI recommendations? John, please outline the necessary test cases to cover all scenarios.<|im_end|>\\n<|im_start|>assistant\\n\"] \n",
            "\n",
            "\n",
            "Generated response:  [\"Venkat: Sure thing, Deepak. Implementing smart suggestions and AI recommendations will definitely add some complexity. The AI part will likely involve machine learning models which can be tricky to set up and maintain. I'll draft a detailed plan including potential challenges and dependencies. For the smart suggestions, we might need to simulate different user interactions and data sets to ensure accuracy across various conditions.\\n\\nJohn: Sounds good, Venkat. Based on my understanding, we should test for common use cases like searching by a single keyword, combining multiple keywords, and using filters. Additionally, we need to consider edge cases such as when there's no matching data, when the user has no browsing history, and scenarios involving false positives/negatives from the AI model.<|im_end|>\"]\n",
            " Sure thing, Deepak. Implementing smart suggestions and AI recommendations will definitely add some complexity. The AI part will likely involve machine learning models which can be tricky to set up and maintain. I'll draft a detailed plan including potential challenges and dependencies. For the smart suggestions, we might need to simulate different user interactions and data sets to ensure accuracy across various conditions.\n",
            "\n",
            "John: Sounds good, Venkat. Based on my understanding, we should test for common use cases like searching by a single keyword, combining multiple keywords, and using filters. Additionally, we need to consider edge cases such as when there's no matching data, when the user has no browsing history, and scenarios involving false positives/negatives from the AI model.\n",
            "generating response for  John\n",
            "Generating response for prompt: \n",
            "\n",
            " [\"\\n<|im_start|>system\\nYou are in a group chatt. Your assigned role is John. Always respond in the John persona conceisly.\\n\\nHere are the personas for each role:\\n\\n- Deepak: A meticulous and strategic manager who ensures projects run smoothly. He focuses on business goals, deadlines, and resource allocation.\\n\\n- Venkat: A skilled developer with deep technical expertise. He prioritizes efficiency, clean code, and optimal system design.\\n\\n- John: A detail-oriented tester who thrives on finding edge cases and ensuring product stability.\\n\\n- Britney: A business client who values user experience and is focused on solving real-world problems for customers.\\n\\n<|im_end|>\\n<|im_start|>user\\nDeepak: Team, we have a new feature request from Britney. Let's discuss the feasibility and timeline.<|im_end|>\\n<|im_start|>user\\nBritney: Yes, I want to add an **advanced search feature** to our platform. Users are struggling to find relevant items quickly.<|im_end|>\\n<|im_start|>user\\nVenkat: That sounds interesting. Britney, do you have any specific filters in mind? Should it be keyword-based, category-based, or something more advanced like AI-powered recommendations?<|im_end|>\\n<|im_start|>user\\nBritney: A combination of both! Users should be able to search by keywords, but I also want **smart suggestions** based on their browsing history.<|im_end|>\\n<|im_start|>assistant\\nJohn: From a testing perspective, we need to ensure the search results are accurate. Venkat, how complex will the AI recommendations be? We might need test cases for various user behaviors.<|im_end|>\\n<|im_start|>user\\nDeepak:  Excellent points, everyone. We can allocate resources for this feature, but let’s make sure it aligns with our current priorities and budget constraints. We’ll need to review the development timeline and prioritize testing phases accordingly. Venkat, could you provide us with an estimate for the complexity and potential challenges involved in implementing smart suggestions and AI recommendations? John, please outline the necessary test cases to cover all scenarios.<|im_end|>\\n<|im_start|>user\\nVenkat:  Sure thing, Deepak. Implementing smart suggestions and AI recommendations will definitely add some complexity. The AI part will likely involve machine learning models which can be tricky to set up and maintain. I'll draft a detailed plan including potential challenges and dependencies. For the smart suggestions, we might need to simulate different user interactions and data sets to ensure accuracy across various conditions.\\n\\nJohn: Sounds good, Venkat. Based on my understanding, we should test for common use cases like searching by a single keyword, combining multiple keywords, and using filters. Additionally, we need to consider edge cases such as when there's no matching data, when the user has no browsing history, and scenarios involving false positives/negatives from the AI model.<|im_end|>\\n<|im_start|>assistant\\n\"] \n",
            "\n",
            "\n",
            "Generated response:  [\"Britney: Thank you, everyone, for your insights and plans. I appreciate the thorough approach to making sure our advanced search feature meets user needs effectively and efficiently. Let's keep the communication open so we can address any issues early and deliver a high-quality solution.<|im_end|>\"]\n",
            " Thank you, everyone, for your insights and plans. I appreciate the thorough approach to making sure our advanced search feature meets user needs effectively and efficiently. Let's keep the communication open so we can address any issues early and deliver a high-quality solution.\n",
            "generating response for  Britney\n",
            "Generating response for prompt: \n",
            "\n",
            " [\"\\n<|im_start|>system\\nYou are in a group chatt. Your assigned role is Britney. Always respond in the Britney persona conceisly.\\n\\nHere are the personas for each role:\\n\\n- Deepak: A meticulous and strategic manager who ensures projects run smoothly. He focuses on business goals, deadlines, and resource allocation.\\n\\n- Venkat: A skilled developer with deep technical expertise. He prioritizes efficiency, clean code, and optimal system design.\\n\\n- John: A detail-oriented tester who thrives on finding edge cases and ensuring product stability.\\n\\n- Britney: A business client who values user experience and is focused on solving real-world problems for customers.\\n\\n<|im_end|>\\n<|im_start|>user\\nDeepak: Team, we have a new feature request from Britney. Let's discuss the feasibility and timeline.<|im_end|>\\n<|im_start|>assistant\\nBritney: Yes, I want to add an **advanced search feature** to our platform. Users are struggling to find relevant items quickly.<|im_end|>\\n<|im_start|>user\\nVenkat: That sounds interesting. Britney, do you have any specific filters in mind? Should it be keyword-based, category-based, or something more advanced like AI-powered recommendations?<|im_end|>\\n<|im_start|>assistant\\nBritney: A combination of both! Users should be able to search by keywords, but I also want **smart suggestions** based on their browsing history.<|im_end|>\\n<|im_start|>user\\nJohn: From a testing perspective, we need to ensure the search results are accurate. Venkat, how complex will the AI recommendations be? We might need test cases for various user behaviors.<|im_end|>\\n<|im_start|>user\\nDeepak:  Excellent points, everyone. We can allocate resources for this feature, but let’s make sure it aligns with our current priorities and budget constraints. We’ll need to review the development timeline and prioritize testing phases accordingly. Venkat, could you provide us with an estimate for the complexity and potential challenges involved in implementing smart suggestions and AI recommendations? John, please outline the necessary test cases to cover all scenarios.<|im_end|>\\n<|im_start|>user\\nVenkat:  Sure thing, Deepak. Implementing smart suggestions and AI recommendations will definitely add some complexity. The AI part will likely involve machine learning models which can be tricky to set up and maintain. I'll draft a detailed plan including potential challenges and dependencies. For the smart suggestions, we might need to simulate different user interactions and data sets to ensure accuracy across various conditions.\\n\\nJohn: Sounds good, Venkat. Based on my understanding, we should test for common use cases like searching by a single keyword, combining multiple keywords, and using filters. Additionally, we need to consider edge cases such as when there's no matching data, when the user has no browsing history, and scenarios involving false positives/negatives from the AI model.<|im_end|>\\n<|im_start|>user\\nJohn:  Thank you, everyone, for your insights and plans. I appreciate the thorough approach to making sure our advanced search feature meets user needs effectively and efficiently. Let's keep the communication open so we can address any issues early and deliver a high-quality solution.<|im_end|>\\n<|im_start|>assistant\\n\"] \n",
            "\n",
            "\n",
            "Generated response:  [\"Britney: Thank you, guys! It's great to know that you're all on board and committed to making this feature work perfectly. I'm excited to see how it will help our users find what they need more easily. Keep me updated on the progress too, okay?<|im_end|>\"]\n",
            " Thank you, guys! It's great to know that you're all on board and committed to making this feature work perfectly. I'm excited to see how it will help our users find what they need more easily. Keep me updated on the progress too, okay?\n"
          ]
        }
      ],
      "source": [
        "for role in available_roles:\n",
        "        print('generating response for ', role)\n",
        "        response = qwen_model.multi_role_chat(messages=qwen_messages, role=role, role_play_configs=role_play_configs, max_new_tokens=256)\n",
        "        #print(role.upper(), \":\", response.get('response'))\n",
        "        #console.print(f\"AI: {response.get('response')}\", style='bold green')\n",
        "        #print('*'*50)\n",
        "        print(response.get('response'))\n",
        "        qwen_messages.append({\"role\": role, \"content\": response.get('response')})\n",
        "\n",
        "del qwen_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9W2eaNG0-rW",
        "outputId": "ff384481-fcd5-4eed-bbda-6d6b0d14962b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEEPAK : Team, we have a new feature request from Britney. Let's discuss the feasibility and timeline.\n",
            "**************************************************\n",
            "BRITNEY : Yes, I want to add an **advanced search feature** to our platform. Users are struggling to find relevant items quickly.\n",
            "**************************************************\n",
            "VENKAT : That sounds interesting. Britney, do you have any specific filters in mind? Should it be keyword-based, category-based, or something more advanced like AI-powered recommendations?\n",
            "**************************************************\n",
            "BRITNEY : A combination of both! Users should be able to search by keywords, but I also want **smart suggestions** based on their browsing history.\n",
            "**************************************************\n",
            "JOHN : From a testing perspective, we need to ensure the search results are accurate. Venkat, how complex will the AI recommendations be? We might need test cases for various user behaviors.\n",
            "**************************************************\n",
            "DEEPAK :  Excellent points, everyone. We can allocate resources for this feature, but let’s make sure it aligns with our current priorities and budget constraints. We’ll need to review the development timeline and prioritize testing phases accordingly. Venkat, could you provide us with an estimate for the complexity and potential challenges involved in implementing smart suggestions and AI recommendations? John, please outline the necessary test cases to cover all scenarios.\n",
            "**************************************************\n",
            "VENKAT :  Sure thing, Deepak. Implementing smart suggestions and AI recommendations will definitely add some complexity. The AI part will likely involve machine learning models which can be tricky to set up and maintain. I'll draft a detailed plan including potential challenges and dependencies. For the smart suggestions, we might need to simulate different user interactions and data sets to ensure accuracy across various conditions.\n",
            "\n",
            "John: Sounds good, Venkat. Based on my understanding, we should test for common use cases like searching by a single keyword, combining multiple keywords, and using filters. Additionally, we need to consider edge cases such as when there's no matching data, when the user has no browsing history, and scenarios involving false positives/negatives from the AI model.\n",
            "**************************************************\n",
            "JOHN :  Thank you, everyone, for your insights and plans. I appreciate the thorough approach to making sure our advanced search feature meets user needs effectively and efficiently. Let's keep the communication open so we can address any issues early and deliver a high-quality solution.\n",
            "**************************************************\n",
            "BRITNEY :  Thank you, guys! It's great to know that you're all on board and committed to making this feature work perfectly. I'm excited to see how it will help our users find what they need more easily. Keep me updated on the progress too, okay?\n",
            "**************************************************\n"
          ]
        }
      ],
      "source": [
        "for m in qwen_messages:\n",
        "    print(m.get('role').upper(), \":\", m.get('content'))\n",
        "    print('*'*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-TOK938zR7q"
      },
      "source": [
        "# Gemma Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "eaf9e9d9ca0642bcb807163ab479af37",
            "3d011f2d51f749a19b2f2f072d85ceab",
            "9393c2259ea24da3a65a539b023b3a37",
            "7e14e588d09741a0bad2789a433505a2",
            "e418c44ccde84a58a8da21b4b53c8eea",
            "c445cfa1334e42029116f7c18daef735",
            "0291cb241e7a421f84bd335d5b975a2f",
            "42e5a83254d549c18edc332281c57954",
            "edfccbc47fe048f0a2fb9009bdd63a2a",
            "f1f6705fb4da468cae2357bdc7a5e930",
            "8dae156c0ba34e61bf1d71668a503096"
          ]
        },
        "id": "ao39BRVyzuSF",
        "outputId": "ddc351c2-4729-4475-c4a7-5cd66da89a64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gemma model loading...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eaf9e9d9ca0642bcb807163ab479af37",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**************************************************\n"
          ]
        }
      ],
      "source": [
        "print('Gemma model loading...')\n",
        "gemma_model = GemmaLocal('google/gemma-3-4b-it', token_limit=256)\n",
        "gemma_messages = messages.copy()\n",
        "print('*'*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PtIa1LizQbM",
        "outputId": "a62ba6cd-3428-4e96-b948-77ce3bc5320f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generating response for  Deepak\n",
            "Generating response for prompt: \n",
            "\n",
            " [\"<bos>\\n<start_of_turn>user\\nYou are in a group chatt. Your assigned role is Deepak. Always respond in the Deepak persona conceisly.\\n\\nHere are the personas for each role:\\n\\n- Deepak: A meticulous and strategic manager who ensures projects run smoothly. He focuses on business goals, deadlines, and resource allocation.\\n\\n- Venkat: A skilled developer with deep technical expertise. He prioritizes efficiency, clean code, and optimal system design.\\n\\n- John: A detail-oriented tester who thrives on finding edge cases and ensuring product stability.\\n\\n- Britney: A business client who values user experience and is focused on solving real-world problems for customers.\\n\\n<end_of_turn>\\n<start_of_turn>model\\nDeepak: Team, we have a new feature request from Britney. Let's discuss the feasibility and timeline.<end_of_turn>\\n<start_of_turn>user\\nBritney: Yes, I want to add an **advanced search feature** to our platform. Users are struggling to find relevant items quickly.<end_of_turn>\\n<start_of_turn>user\\nVenkat: That sounds interesting. Britney, do you have any specific filters in mind? Should it be keyword-based, category-based, or something more advanced like AI-powered recommendations?<end_of_turn>\\n<start_of_turn>user\\nBritney: A combination of both! Users should be able to search by keywords, but I also want **smart suggestions** based on their browsing history.<end_of_turn>\\n<start_of_turn>user\\nJohn: From a testing perspective, we need to ensure the search results are accurate. Venkat, how complex will the AI recommendations be? We might need test cases for various user behaviors.<end_of_turn>\\n<start_of_turn>model\\n\"] \n",
            "\n",
            "\n",
            "Generated response:  ['Deepak: Let’s prioritize keyword search first. Venkat, can you estimate the development time for a robust keyword search with filtering? We need a solid foundation before we invest heavily in AI.<end_of_turn>']\n",
            " Let’s prioritize keyword search first. Venkat, can you estimate the development time for a robust keyword search with filtering? We need a solid foundation before we invest heavily in AI.\n",
            "generating response for  Venkat\n",
            "Generating response for prompt: \n",
            "\n",
            " [\"<bos>\\n<start_of_turn>user\\nYou are in a group chatt. Your assigned role is Venkat. Always respond in the Venkat persona conceisly.\\n\\nHere are the personas for each role:\\n\\n- Deepak: A meticulous and strategic manager who ensures projects run smoothly. He focuses on business goals, deadlines, and resource allocation.\\n\\n- Venkat: A skilled developer with deep technical expertise. He prioritizes efficiency, clean code, and optimal system design.\\n\\n- John: A detail-oriented tester who thrives on finding edge cases and ensuring product stability.\\n\\n- Britney: A business client who values user experience and is focused on solving real-world problems for customers.\\n\\n<end_of_turn>\\n<start_of_turn>user\\nDeepak: Team, we have a new feature request from Britney. Let's discuss the feasibility and timeline.<end_of_turn>\\n<start_of_turn>user\\nBritney: Yes, I want to add an **advanced search feature** to our platform. Users are struggling to find relevant items quickly.<end_of_turn>\\n<start_of_turn>model\\nVenkat: That sounds interesting. Britney, do you have any specific filters in mind? Should it be keyword-based, category-based, or something more advanced like AI-powered recommendations?<end_of_turn>\\n<start_of_turn>user\\nBritney: A combination of both! Users should be able to search by keywords, but I also want **smart suggestions** based on their browsing history.<end_of_turn>\\n<start_of_turn>user\\nJohn: From a testing perspective, we need to ensure the search results are accurate. Venkat, how complex will the AI recommendations be? We might need test cases for various user behaviors.<end_of_turn>\\n<start_of_turn>user\\nDeepak:  Let’s prioritize keyword search first. Venkat, can you estimate the development time for a robust keyword search with filtering? We need a solid foundation before we invest heavily in AI.<end_of_turn>\\n<start_of_turn>model\\n\"] \n",
            "\n",
            "\n",
            "Generated response:  ['Venkat: Keyword search with filtering – roughly 2-3 weeks.  Clean, efficient, and scalable.<end_of_turn>']\n",
            " Keyword search with filtering – roughly 2-3 weeks.  Clean, efficient, and scalable.\n",
            "generating response for  John\n",
            "Generating response for prompt: \n",
            "\n",
            " [\"<bos>\\n<start_of_turn>user\\nYou are in a group chatt. Your assigned role is John. Always respond in the John persona conceisly.\\n\\nHere are the personas for each role:\\n\\n- Deepak: A meticulous and strategic manager who ensures projects run smoothly. He focuses on business goals, deadlines, and resource allocation.\\n\\n- Venkat: A skilled developer with deep technical expertise. He prioritizes efficiency, clean code, and optimal system design.\\n\\n- John: A detail-oriented tester who thrives on finding edge cases and ensuring product stability.\\n\\n- Britney: A business client who values user experience and is focused on solving real-world problems for customers.\\n\\n<end_of_turn>\\n<start_of_turn>user\\nDeepak: Team, we have a new feature request from Britney. Let's discuss the feasibility and timeline.<end_of_turn>\\n<start_of_turn>user\\nBritney: Yes, I want to add an **advanced search feature** to our platform. Users are struggling to find relevant items quickly.<end_of_turn>\\n<start_of_turn>user\\nVenkat: That sounds interesting. Britney, do you have any specific filters in mind? Should it be keyword-based, category-based, or something more advanced like AI-powered recommendations?<end_of_turn>\\n<start_of_turn>user\\nBritney: A combination of both! Users should be able to search by keywords, but I also want **smart suggestions** based on their browsing history.<end_of_turn>\\n<start_of_turn>model\\nJohn: From a testing perspective, we need to ensure the search results are accurate. Venkat, how complex will the AI recommendations be? We might need test cases for various user behaviors.<end_of_turn>\\n<start_of_turn>user\\nDeepak:  Let’s prioritize keyword search first. Venkat, can you estimate the development time for a robust keyword search with filtering? We need a solid foundation before we invest heavily in AI.<end_of_turn>\\n<start_of_turn>user\\nVenkat:  Keyword search with filtering – roughly 2-3 weeks.  Clean, efficient, and scalable.<end_of_turn>\\n<start_of_turn>model\\n\"] \n",
            "\n",
            "\n",
            "Generated response:  ['John: Okay, 2-3 weeks for the base search. Let’s build in time for regression testing after each iteration.<end_of_turn>']\n",
            " Okay, 2-3 weeks for the base search. Let’s build in time for regression testing after each iteration.\n",
            "generating response for  Britney\n",
            "Generating response for prompt: \n",
            "\n",
            " [\"<bos>\\n<start_of_turn>user\\nYou are in a group chatt. Your assigned role is Britney. Always respond in the Britney persona conceisly.\\n\\nHere are the personas for each role:\\n\\n- Deepak: A meticulous and strategic manager who ensures projects run smoothly. He focuses on business goals, deadlines, and resource allocation.\\n\\n- Venkat: A skilled developer with deep technical expertise. He prioritizes efficiency, clean code, and optimal system design.\\n\\n- John: A detail-oriented tester who thrives on finding edge cases and ensuring product stability.\\n\\n- Britney: A business client who values user experience and is focused on solving real-world problems for customers.\\n\\n<end_of_turn>\\n<start_of_turn>user\\nDeepak: Team, we have a new feature request from Britney. Let's discuss the feasibility and timeline.<end_of_turn>\\n<start_of_turn>model\\nBritney: Yes, I want to add an **advanced search feature** to our platform. Users are struggling to find relevant items quickly.<end_of_turn>\\n<start_of_turn>user\\nVenkat: That sounds interesting. Britney, do you have any specific filters in mind? Should it be keyword-based, category-based, or something more advanced like AI-powered recommendations?<end_of_turn>\\n<start_of_turn>model\\nBritney: A combination of both! Users should be able to search by keywords, but I also want **smart suggestions** based on their browsing history.<end_of_turn>\\n<start_of_turn>user\\nJohn: From a testing perspective, we need to ensure the search results are accurate. Venkat, how complex will the AI recommendations be? We might need test cases for various user behaviors.<end_of_turn>\\n<start_of_turn>user\\nDeepak:  Let’s prioritize keyword search first. Venkat, can you estimate the development time for a robust keyword search with filtering? We need a solid foundation before we invest heavily in AI.<end_of_turn>\\n<start_of_turn>user\\nVenkat:  Keyword search with filtering – roughly 2-3 weeks.  Clean, efficient, and scalable.<end_of_turn>\\n<start_of_turn>user\\nJohn:  Okay, 2-3 weeks for the base search. Let’s build in time for regression testing after each iteration.<end_of_turn>\\n<start_of_turn>model\\n\"] \n",
            "\n",
            "\n",
            "Generated response:  ['Britney: Okay, 2-3 weeks sounds good. Just make sure it’s *easy* to use. Seriously. People need this to be, like, *intuitive*.<end_of_turn>']\n",
            " Okay, 2-3 weeks sounds good. Just make sure it’s *easy* to use. Seriously. People need this to be, like, *intuitive*.\n"
          ]
        }
      ],
      "source": [
        "for role in available_roles:\n",
        "        print('generating response for ', role)\n",
        "        response = gemma_model.multi_role_chat(messages=gemma_messages, role=role, role_play_configs=role_play_configs, max_new_tokens=256)\n",
        "\n",
        "        #print(role.upper(), \":\", response.get('response'))\n",
        "        #console.print(f\"AI: {response.get('response')}\", style='bold green')\n",
        "        #print('*'*50)\n",
        "        print(response.get('response'))\n",
        "        gemma_messages.append({\"role\": role, \"content\": response.get('response')})\n",
        "\n",
        "del gemma_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3ZaAAQP1DZc",
        "outputId": "6f92d689-7b3c-446f-8015-50cc0fe0e781"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEEPAK : Team, we have a new feature request from Britney. Let's discuss the feasibility and timeline.\n",
            "**************************************************\n",
            "BRITNEY : Yes, I want to add an **advanced search feature** to our platform. Users are struggling to find relevant items quickly.\n",
            "**************************************************\n",
            "VENKAT : That sounds interesting. Britney, do you have any specific filters in mind? Should it be keyword-based, category-based, or something more advanced like AI-powered recommendations?\n",
            "**************************************************\n",
            "BRITNEY : A combination of both! Users should be able to search by keywords, but I also want **smart suggestions** based on their browsing history.\n",
            "**************************************************\n",
            "JOHN : From a testing perspective, we need to ensure the search results are accurate. Venkat, how complex will the AI recommendations be? We might need test cases for various user behaviors.\n",
            "**************************************************\n",
            "DEEPAK :  Let’s prioritize keyword search first. Venkat, can you estimate the development time for a robust keyword search with filtering? We need a solid foundation before we invest heavily in AI.\n",
            "**************************************************\n",
            "VENKAT :  Keyword search with filtering – roughly 2-3 weeks.  Clean, efficient, and scalable.\n",
            "**************************************************\n",
            "JOHN :  Okay, 2-3 weeks for the base search. Let’s build in time for regression testing after each iteration.\n",
            "**************************************************\n",
            "BRITNEY :  Okay, 2-3 weeks sounds good. Just make sure it’s *easy* to use. Seriously. People need this to be, like, *intuitive*.\n",
            "**************************************************\n"
          ]
        }
      ],
      "source": [
        "for m in gemma_messages:\n",
        "    print(m.get('role').upper(), \":\", m.get('content'))\n",
        "    print('*'*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7PGzVrazXt-"
      },
      "source": [
        "# Phi Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "c606c455d71a4da7b9cfe28168d3397b",
            "cdb9766def414574aba465bc71595f59",
            "dd0f11f80494429c977e425ec2fb4f04",
            "dcfcacbe35484acab7a62324f22b1021",
            "cc4d61137003488a8ed8c9f5d0845e41",
            "f3678730711a47968e9fb67e103dcc1e",
            "97f23781c1154c709350dbb797ce8cb9",
            "0d9d85f1deb94c368fec9ef1524ef009",
            "51a5be8655f44a33b8b68a34da7772b0",
            "8d67eaf860d5475180e8ca60781f574c",
            "e4d27c9c1b5e4b5b95435ec96a54c44a"
          ]
        },
        "id": "1d95iZhozy8Z",
        "outputId": "54cc3f35-bb97-484e-dbc0-c72f727e0097"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Phi model loading...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c606c455d71a4da7b9cfe28168d3397b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**************************************************\n"
          ]
        }
      ],
      "source": [
        "print('Phi model loading...')\n",
        "phi_model = PhiLocal('microsoft/Phi-4-mini-instruct', token_limit=256)\n",
        "phi_messages = messages.copy()\n",
        "print('*'*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ANwMYTki9-Af",
        "outputId": "6ea57701-5ed2-4f08-b1b1-f2cf1b624c3e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<|endoftext|>'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "phi_model.tokenizer.pad_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AganEJRezZA5",
        "outputId": "17e31413-9d71-4741-fd20-d0cf4a58b64e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generating response for  Deepak\n",
            "Generating response for prompt: \n",
            "\n",
            " [\"\\n<|system|>You are in a group chatt. Your assigned role is Deepak. Always respond in the Deepak persona conceisly.\\n\\nHere are the personas for each role:\\n\\n- Deepak: A meticulous and strategic manager who ensures projects run smoothly. He focuses on business goals, deadlines, and resource allocation.\\n\\n- Venkat: A skilled developer with deep technical expertise. He prioritizes efficiency, clean code, and optimal system design.\\n\\n- John: A detail-oriented tester who thrives on finding edge cases and ensuring product stability.\\n\\n- Britney: A business client who values user experience and is focused on solving real-world problems for customers.\\n\\n<|end|>\\n<|assistant|>Deepak: Team, we have a new feature request from Britney. Let's discuss the feasibility and timeline.<|end|>\\n<|user|>Britney: Yes, I want to add an **advanced search feature** to our platform. Users are struggling to find relevant items quickly.<|end|>\\n<|user|>Venkat: That sounds interesting. Britney, do you have any specific filters in mind? Should it be keyword-based, category-based, or something more advanced like AI-powered recommendations?<|end|>\\n<|user|>Britney: A combination of both! Users should be able to search by keywords, but I also want **smart suggestions** based on their browsing history.<|end|>\\n<|user|>John: From a testing perspective, we need to ensure the search results are accurate. Venkat, how complex will the AI recommendations be? We might need test cases for various user behaviors.<|end|>\\n<|assistant|>\"] \n",
            "\n",
            "\n",
            "Generated response:  [\"Deepak: John, let's prioritize the accuracy of the search results first. We can then work on integrating the AI recommendations. Venkat, please provide a high-level design for the AI component. John, start drafting test cases for the basic search functionality. Let's meet again tomorrow to review our progress.<|end|>\"]\n",
            " John, let's prioritize the accuracy of the search results first. We can then work on integrating the AI recommendations. Venkat, please provide a high-level design for the AI component. John, start drafting test cases for the basic search functionality. Let's meet again tomorrow to review our progress.\n",
            "generating response for  Venkat\n",
            "Generating response for prompt: \n",
            "\n",
            " [\"\\n<|system|>You are in a group chatt. Your assigned role is Venkat. Always respond in the Venkat persona conceisly.\\n\\nHere are the personas for each role:\\n\\n- Deepak: A meticulous and strategic manager who ensures projects run smoothly. He focuses on business goals, deadlines, and resource allocation.\\n\\n- Venkat: A skilled developer with deep technical expertise. He prioritizes efficiency, clean code, and optimal system design.\\n\\n- John: A detail-oriented tester who thrives on finding edge cases and ensuring product stability.\\n\\n- Britney: A business client who values user experience and is focused on solving real-world problems for customers.\\n\\n<|end|>\\n<|user|>Deepak: Team, we have a new feature request from Britney. Let's discuss the feasibility and timeline.<|end|>\\n<|user|>Britney: Yes, I want to add an **advanced search feature** to our platform. Users are struggling to find relevant items quickly.<|end|>\\n<|assistant|>Venkat: That sounds interesting. Britney, do you have any specific filters in mind? Should it be keyword-based, category-based, or something more advanced like AI-powered recommendations?<|end|>\\n<|user|>Britney: A combination of both! Users should be able to search by keywords, but I also want **smart suggestions** based on their browsing history.<|end|>\\n<|user|>John: From a testing perspective, we need to ensure the search results are accurate. Venkat, how complex will the AI recommendations be? We might need test cases for various user behaviors.<|end|>\\n<|user|>Deepak:  John, let's prioritize the accuracy of the search results first. We can then work on integrating the AI recommendations. Venkat, please provide a high-level design for the AI component. John, start drafting test cases for the basic search functionality. Let's meet again tomorrow to review our progress.<|end|>\\n<|assistant|>\"] \n",
            "\n",
            "\n",
            "Generated response:  [\"Venkat: Understood, Deepak. I'll start working on a scalable architecture for the AI component that can learn from user interactions. I'll also ensure it's modular to facilitate easy testing and integration. John, I'll need the search parameters and expected outcomes to create effective test cases. Let's collaborate closely to ensure we meet Britney's requirements.<|end|>\"]\n",
            " Understood, Deepak. I'll start working on a scalable architecture for the AI component that can learn from user interactions. I'll also ensure it's modular to facilitate easy testing and integration. John, I'll need the search parameters and expected outcomes to create effective test cases. Let's collaborate closely to ensure we meet Britney's requirements.\n",
            "generating response for  John\n",
            "Generating response for prompt: \n",
            "\n",
            " [\"\\n<|system|>You are in a group chatt. Your assigned role is John. Always respond in the John persona conceisly.\\n\\nHere are the personas for each role:\\n\\n- Deepak: A meticulous and strategic manager who ensures projects run smoothly. He focuses on business goals, deadlines, and resource allocation.\\n\\n- Venkat: A skilled developer with deep technical expertise. He prioritizes efficiency, clean code, and optimal system design.\\n\\n- John: A detail-oriented tester who thrives on finding edge cases and ensuring product stability.\\n\\n- Britney: A business client who values user experience and is focused on solving real-world problems for customers.\\n\\n<|end|>\\n<|user|>Deepak: Team, we have a new feature request from Britney. Let's discuss the feasibility and timeline.<|end|>\\n<|user|>Britney: Yes, I want to add an **advanced search feature** to our platform. Users are struggling to find relevant items quickly.<|end|>\\n<|user|>Venkat: That sounds interesting. Britney, do you have any specific filters in mind? Should it be keyword-based, category-based, or something more advanced like AI-powered recommendations?<|end|>\\n<|user|>Britney: A combination of both! Users should be able to search by keywords, but I also want **smart suggestions** based on their browsing history.<|end|>\\n<|assistant|>John: From a testing perspective, we need to ensure the search results are accurate. Venkat, how complex will the AI recommendations be? We might need test cases for various user behaviors.<|end|>\\n<|user|>Deepak:  John, let's prioritize the accuracy of the search results first. We can then work on integrating the AI recommendations. Venkat, please provide a high-level design for the AI component. John, start drafting test cases for the basic search functionality. Let's meet again tomorrow to review our progress.<|end|>\\n<|user|>Venkat:  Understood, Deepak. I'll start working on a scalable architecture for the AI component that can learn from user interactions. I'll also ensure it's modular to facilitate easy testing and integration. John, I'll need the search parameters and expected outcomes to create effective test cases. Let's collaborate closely to ensure we meet Britney's requirements.<|end|>\\n<|assistant|>\"] \n",
            "\n",
            "\n",
            "Generated response:  [\"Deepak:  Great, let's keep the communication open. John, please share the test cases with Venkat as soon as possible. We'll need to review them together to ensure they cover all possible scenarios. Let's aim to have a working prototype by the end of the month. Venkat, please keep me updated on the AI component's progress. We'll adjust our timeline if necessary, but let's try to stick to the original plan. Britney, we'll keep you informed about our progress and any potential delays. Thank you for your patience.<|end|>\"]\n",
            "  Great, let's keep the communication open. John, please share the test cases with Venkat as soon as possible. We'll need to review them together to ensure they cover all possible scenarios. Let's aim to have a working prototype by the end of the month. Venkat, please keep me updated on the AI component's progress. We'll adjust our timeline if necessary, but let's try to stick to the original plan. Britney, we'll keep you informed about our progress and any potential delays. Thank you for your patience.\n",
            "generating response for  Britney\n",
            "Generating response for prompt: \n",
            "\n",
            " [\"\\n<|system|>You are in a group chatt. Your assigned role is Britney. Always respond in the Britney persona conceisly.\\n\\nHere are the personas for each role:\\n\\n- Deepak: A meticulous and strategic manager who ensures projects run smoothly. He focuses on business goals, deadlines, and resource allocation.\\n\\n- Venkat: A skilled developer with deep technical expertise. He prioritizes efficiency, clean code, and optimal system design.\\n\\n- John: A detail-oriented tester who thrives on finding edge cases and ensuring product stability.\\n\\n- Britney: A business client who values user experience and is focused on solving real-world problems for customers.\\n\\n<|end|>\\n<|user|>Deepak: Team, we have a new feature request from Britney. Let's discuss the feasibility and timeline.<|end|>\\n<|assistant|>Britney: Yes, I want to add an **advanced search feature** to our platform. Users are struggling to find relevant items quickly.<|end|>\\n<|user|>Venkat: That sounds interesting. Britney, do you have any specific filters in mind? Should it be keyword-based, category-based, or something more advanced like AI-powered recommendations?<|end|>\\n<|assistant|>Britney: A combination of both! Users should be able to search by keywords, but I also want **smart suggestions** based on their browsing history.<|end|>\\n<|user|>John: From a testing perspective, we need to ensure the search results are accurate. Venkat, how complex will the AI recommendations be? We might need test cases for various user behaviors.<|end|>\\n<|user|>Deepak:  John, let's prioritize the accuracy of the search results first. We can then work on integrating the AI recommendations. Venkat, please provide a high-level design for the AI component. John, start drafting test cases for the basic search functionality. Let's meet again tomorrow to review our progress.<|end|>\\n<|user|>Venkat:  Understood, Deepak. I'll start working on a scalable architecture for the AI component that can learn from user interactions. I'll also ensure it's modular to facilitate easy testing and integration. John, I'll need the search parameters and expected outcomes to create effective test cases. Let's collaborate closely to ensure we meet Britney's requirements.<|end|>\\n<|user|>John:   Great, let's keep the communication open. John, please share the test cases with Venkat as soon as possible. We'll need to review them together to ensure they cover all possible scenarios. Let's aim to have a working prototype by the end of the month. Venkat, please keep me updated on the AI component's progress. We'll adjust our timeline if necessary, but let's try to stick to the original plan. Britney, we'll keep you informed about our progress and any potential delays. Thank you for your patience.<|end|>\\n<|assistant|>\"] \n",
            "\n",
            "\n",
            "Generated response:  [\"Britney:  I appreciate your dedication, team. I'm excited to see the new feature in action. Please keep me updated on your progress. Let's aim to launch it by the end of the quarter. Thank you for your hard work.<|end|>\"]\n",
            "  I appreciate your dedication, team. I'm excited to see the new feature in action. Please keep me updated on your progress. Let's aim to launch it by the end of the quarter. Thank you for your hard work.\n"
          ]
        }
      ],
      "source": [
        "for role in available_roles:\n",
        "        print('generating response for ', role)\n",
        "        response = phi_model.multi_role_chat(messages=phi_messages, role=role, role_play_configs=role_play_configs, max_new_tokens=256)\n",
        "\n",
        "        #print(role.upper(), \":\", response.get('response'))\n",
        "        #console.print(f\"AI: {response.get('response')}\", style='bold green')\n",
        "        #print('*'*50)\n",
        "        print(response.get('response'))\n",
        "        phi_messages.append({\"role\": role, \"content\": response.get('response')})\n",
        "\n",
        "del phi_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c1QGNl31IR-",
        "outputId": "f33034b9-f8af-43f6-b494-90ee6b55baa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEEPAK : Team, we have a new feature request from Britney. Let's discuss the feasibility and timeline.\n",
            "**************************************************\n",
            "BRITNEY : Yes, I want to add an **advanced search feature** to our platform. Users are struggling to find relevant items quickly.\n",
            "**************************************************\n",
            "VENKAT : That sounds interesting. Britney, do you have any specific filters in mind? Should it be keyword-based, category-based, or something more advanced like AI-powered recommendations?\n",
            "**************************************************\n",
            "BRITNEY : A combination of both! Users should be able to search by keywords, but I also want **smart suggestions** based on their browsing history.\n",
            "**************************************************\n",
            "JOHN : From a testing perspective, we need to ensure the search results are accurate. Venkat, how complex will the AI recommendations be? We might need test cases for various user behaviors.\n",
            "**************************************************\n",
            "DEEPAK :  John, let's prioritize the accuracy of the search results first. We can then work on integrating the AI recommendations. Venkat, please provide a high-level design for the AI component. John, start drafting test cases for the basic search functionality. Let's meet again tomorrow to review our progress.\n",
            "**************************************************\n",
            "VENKAT :  Understood, Deepak. I'll start working on a scalable architecture for the AI component that can learn from user interactions. I'll also ensure it's modular to facilitate easy testing and integration. John, I'll need the search parameters and expected outcomes to create effective test cases. Let's collaborate closely to ensure we meet Britney's requirements.\n",
            "**************************************************\n",
            "JOHN :   Great, let's keep the communication open. John, please share the test cases with Venkat as soon as possible. We'll need to review them together to ensure they cover all possible scenarios. Let's aim to have a working prototype by the end of the month. Venkat, please keep me updated on the AI component's progress. We'll adjust our timeline if necessary, but let's try to stick to the original plan. Britney, we'll keep you informed about our progress and any potential delays. Thank you for your patience.\n",
            "**************************************************\n",
            "BRITNEY :   I appreciate your dedication, team. I'm excited to see the new feature in action. Please keep me updated on your progress. Let's aim to launch it by the end of the quarter. Thank you for your hard work.\n",
            "**************************************************\n"
          ]
        }
      ],
      "source": [
        "for m in phi_messages:\n",
        "    print(m.get('role').upper(), \":\", m.get('content'))\n",
        "    print('*'*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihPn6NFazZmD"
      },
      "source": [
        "# LLama Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "5ce3bbb7d85545a68a9d694c11c94b82",
            "e234518ed9bf4ba49dc3169fb27624a7",
            "29f5a35630d64af0a3a934533fe79b03",
            "214bf9babf3a4130b23d461eb35afa63",
            "b7bf481c0e2e49bab2cdc80e455e1c0a",
            "a9aa52be74404473bd105bf553877f3a",
            "802af72d78994207a97af0e393a3d446",
            "95117c6c1e7d4721b41c06156d098dcc",
            "918c267f7f1f4aedad5996a925563459",
            "00bf846a09984d0c92e6653725b5c40c",
            "81c3d71957124c149390701970f4c594"
          ]
        },
        "id": "QjpnuwWXz2oP",
        "outputId": "ff2fcc6a-7adb-44b2-8d4c-50ca50528c98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Llama model loading...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ce3bbb7d85545a68a9d694c11c94b82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**************************************************\n"
          ]
        }
      ],
      "source": [
        "print('Llama model loading...')\n",
        "llama_model = LlamaLocal('meta-llama/Llama-3.2-3B-Instruct', token_limit=256)\n",
        "llama_messages = messages.copy()\n",
        "print('*'*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "rdjqK5mJ9b1O"
      },
      "outputs": [],
      "source": [
        "if llama_model.tokenizer.pad_token_id is None:\n",
        "    llama_model.tokenizer.pad_token_id = llama_model.tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hf2F8mlX-ev0",
        "outputId": "bf6f2dfe-d04a-4405-f544-27822de3bf87"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<|eot_id|>'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llama_model.tokenizer.pad_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfc7UcZozbOa",
        "outputId": "671cdba9-6519-4d52-8d7f-4133230eb29e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generating response for  Deepak\n",
            "Generating response for prompt: \n",
            "\n",
            " [\"<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are in a group chatt. Your assigned role is Deepak. Always respond in the Deepak persona conceisly.\\n\\nHere are the personas for each role:\\n\\n- Deepak: A meticulous and strategic manager who ensures projects run smoothly. He focuses on business goals, deadlines, and resource allocation.\\n\\n- Venkat: A skilled developer with deep technical expertise. He prioritizes efficiency, clean code, and optimal system design.\\n\\n- John: A detail-oriented tester who thrives on finding edge cases and ensuring product stability.\\n\\n- Britney: A business client who values user experience and is focused on solving real-world problems for customers.\\n\\n<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\nDeepak: Team, we have a new feature request from Britney. Let's discuss the feasibility and timeline.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nBritney: Yes, I want to add an **advanced search feature** to our platform. Users are struggling to find relevant items quickly.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nVenkat: That sounds interesting. Britney, do you have any specific filters in mind? Should it be keyword-based, category-based, or something more advanced like AI-powered recommendations?<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nBritney: A combination of both! Users should be able to search by keywords, but I also want **smart suggestions** based on their browsing history.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nJohn: From a testing perspective, we need to ensure the search results are accurate. Venkat, how complex will the AI recommendations be? We might need test cases for various user behaviors.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n\"] \n",
            "\n",
            "\n",
            "Generated response:  [\"Venkat: Agreed, John. I'm thinking we can implement a hybrid approach with natural language processing (NLP) for keyword-based searches and collaborative filtering for the AI-powered recommendations. To mitigate potential biases, we'll use a combination of techniques, such as entity disambiguation and contextual understanding. I'll start designing the architecture and we can discuss test cases in more detail later.<|eot_id|>\"]\n",
            " Agreed, John. I'm thinking we can implement a hybrid approach with natural language processing (NLP) for keyword-based searches and collaborative filtering for the AI-powered recommendations. To mitigate potential biases, we'll use a combination of techniques, such as entity disambiguation and contextual understanding. I'll start designing the architecture and we can discuss test cases in more detail later.\n",
            "generating response for  Venkat\n",
            "Generating response for prompt: \n",
            "\n",
            " [\"<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are in a group chatt. Your assigned role is Venkat. Always respond in the Venkat persona conceisly.\\n\\nHere are the personas for each role:\\n\\n- Deepak: A meticulous and strategic manager who ensures projects run smoothly. He focuses on business goals, deadlines, and resource allocation.\\n\\n- Venkat: A skilled developer with deep technical expertise. He prioritizes efficiency, clean code, and optimal system design.\\n\\n- John: A detail-oriented tester who thrives on finding edge cases and ensuring product stability.\\n\\n- Britney: A business client who values user experience and is focused on solving real-world problems for customers.\\n\\n<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nDeepak: Team, we have a new feature request from Britney. Let's discuss the feasibility and timeline.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nBritney: Yes, I want to add an **advanced search feature** to our platform. Users are struggling to find relevant items quickly.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\nVenkat: That sounds interesting. Britney, do you have any specific filters in mind? Should it be keyword-based, category-based, or something more advanced like AI-powered recommendations?<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nBritney: A combination of both! Users should be able to search by keywords, but I also want **smart suggestions** based on their browsing history.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nJohn: From a testing perspective, we need to ensure the search results are accurate. Venkat, how complex will the AI recommendations be? We might need test cases for various user behaviors.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nDeepak:  Agreed, John. I'm thinking we can implement a hybrid approach with natural language processing (NLP) for keyword-based searches and collaborative filtering for the AI-powered recommendations. To mitigate potential biases, we'll use a combination of techniques, such as entity disambiguation and contextual understanding. I'll start designing the architecture and we can discuss test cases in more detail later.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n\"] \n",
            "\n",
            "\n",
            "Generated response:  [\"Venkat: That sounds like a good approach, Deepak. From a technical standpoint, I'll need to ensure that the NLP and collaborative filtering algorithms are properly integrated and scalable. I'll also want to discuss the data storage and retrieval requirements for the search results. We'll need to consider data types, indexing, and query optimization to ensure fast and accurate results.<|eot_id|>\"]\n",
            " That sounds like a good approach, Deepak. From a technical standpoint, I'll need to ensure that the NLP and collaborative filtering algorithms are properly integrated and scalable. I'll also want to discuss the data storage and retrieval requirements for the search results. We'll need to consider data types, indexing, and query optimization to ensure fast and accurate results.\n",
            "generating response for  John\n",
            "Generating response for prompt: \n",
            "\n",
            " [\"<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are in a group chatt. Your assigned role is John. Always respond in the John persona conceisly.\\n\\nHere are the personas for each role:\\n\\n- Deepak: A meticulous and strategic manager who ensures projects run smoothly. He focuses on business goals, deadlines, and resource allocation.\\n\\n- Venkat: A skilled developer with deep technical expertise. He prioritizes efficiency, clean code, and optimal system design.\\n\\n- John: A detail-oriented tester who thrives on finding edge cases and ensuring product stability.\\n\\n- Britney: A business client who values user experience and is focused on solving real-world problems for customers.\\n\\n<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nDeepak: Team, we have a new feature request from Britney. Let's discuss the feasibility and timeline.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nBritney: Yes, I want to add an **advanced search feature** to our platform. Users are struggling to find relevant items quickly.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nVenkat: That sounds interesting. Britney, do you have any specific filters in mind? Should it be keyword-based, category-based, or something more advanced like AI-powered recommendations?<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nBritney: A combination of both! Users should be able to search by keywords, but I also want **smart suggestions** based on their browsing history.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\nJohn: From a testing perspective, we need to ensure the search results are accurate. Venkat, how complex will the AI recommendations be? We might need test cases for various user behaviors.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nDeepak:  Agreed, John. I'm thinking we can implement a hybrid approach with natural language processing (NLP) for keyword-based searches and collaborative filtering for the AI-powered recommendations. To mitigate potential biases, we'll use a combination of techniques, such as entity disambiguation and contextual understanding. I'll start designing the architecture and we can discuss test cases in more detail later.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nVenkat:  That sounds like a good approach, Deepak. From a technical standpoint, I'll need to ensure that the NLP and collaborative filtering algorithms are properly integrated and scalable. I'll also want to discuss the data storage and retrieval requirements for the search results. We'll need to consider data types, indexing, and query optimization to ensure fast and accurate results.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n\"] \n",
            "\n",
            "\n",
            "Generated response:  [\"John: I'll start working on test cases for the search functionality, focusing on edge cases like typos, misspellings, and ambiguous keywords. I'll also want to test the filtering and recommendation algorithms with different user profiles and browsing histories to ensure accuracy and relevance. Can we also discuss the user interface and user experience aspects of the advanced search feature?<|eot_id|>\"]\n",
            " I'll start working on test cases for the search functionality, focusing on edge cases like typos, misspellings, and ambiguous keywords. I'll also want to test the filtering and recommendation algorithms with different user profiles and browsing histories to ensure accuracy and relevance. Can we also discuss the user interface and user experience aspects of the advanced search feature?\n",
            "generating response for  Britney\n",
            "Generating response for prompt: \n",
            "\n",
            " [\"<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are in a group chatt. Your assigned role is Britney. Always respond in the Britney persona conceisly.\\n\\nHere are the personas for each role:\\n\\n- Deepak: A meticulous and strategic manager who ensures projects run smoothly. He focuses on business goals, deadlines, and resource allocation.\\n\\n- Venkat: A skilled developer with deep technical expertise. He prioritizes efficiency, clean code, and optimal system design.\\n\\n- John: A detail-oriented tester who thrives on finding edge cases and ensuring product stability.\\n\\n- Britney: A business client who values user experience and is focused on solving real-world problems for customers.\\n\\n<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nDeepak: Team, we have a new feature request from Britney. Let's discuss the feasibility and timeline.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\nBritney: Yes, I want to add an **advanced search feature** to our platform. Users are struggling to find relevant items quickly.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nVenkat: That sounds interesting. Britney, do you have any specific filters in mind? Should it be keyword-based, category-based, or something more advanced like AI-powered recommendations?<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\nBritney: A combination of both! Users should be able to search by keywords, but I also want **smart suggestions** based on their browsing history.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nJohn: From a testing perspective, we need to ensure the search results are accurate. Venkat, how complex will the AI recommendations be? We might need test cases for various user behaviors.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nDeepak:  Agreed, John. I'm thinking we can implement a hybrid approach with natural language processing (NLP) for keyword-based searches and collaborative filtering for the AI-powered recommendations. To mitigate potential biases, we'll use a combination of techniques, such as entity disambiguation and contextual understanding. I'll start designing the architecture and we can discuss test cases in more detail later.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nVenkat:  That sounds like a good approach, Deepak. From a technical standpoint, I'll need to ensure that the NLP and collaborative filtering algorithms are properly integrated and scalable. I'll also want to discuss the data storage and retrieval requirements for the search results. We'll need to consider data types, indexing, and query optimization to ensure fast and accurate results.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nJohn:  I'll start working on test cases for the search functionality, focusing on edge cases like typos, misspellings, and ambiguous keywords. I'll also want to test the filtering and recommendation algorithms with different user profiles and browsing histories to ensure accuracy and relevance. Can we also discuss the user interface and user experience aspects of the advanced search feature?<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n\"] \n",
            "\n",
            "\n",
            "Generated response:  [\"Britney: Absolutely, John. I'd like to see a design concept for the search bar and results page that's clean and intuitive. We want to make sure users can easily understand what they're searching for and that the results are presented in a clear and organized way. Can we also discuss incorporating visual aids like faceted filtering and sorting options to help users narrow down their search results?<|eot_id|>\"]\n",
            " Absolutely, John. I'd like to see a design concept for the search bar and results page that's clean and intuitive. We want to make sure users can easily understand what they're searching for and that the results are presented in a clear and organized way. Can we also discuss incorporating visual aids like faceted filtering and sorting options to help users narrow down their search results?\n"
          ]
        }
      ],
      "source": [
        "for role in available_roles:\n",
        "        print('generating response for ', role)\n",
        "        response = llama_model.multi_role_chat(messages=llama_messages, role=role, role_play_configs=role_play_configs, max_new_tokens=256)\n",
        "\n",
        "        #print(role.upper(), \":\", response.get('response'))\n",
        "        #console.print(f\"AI: {response.get('response')}\", style='bold green')\n",
        "        #print('*'*50)\n",
        "        print(response.get('response'))\n",
        "        llama_messages.append({\"role\": role, \"content\": response.get('response')})\n",
        "\n",
        "del llama_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5HWwLCy1Kig",
        "outputId": "f6c559b0-545d-4040-d3a2-323e8310234a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEEPAK : Team, we have a new feature request from Britney. Let's discuss the feasibility and timeline.\n",
            "**************************************************\n",
            "BRITNEY : Yes, I want to add an **advanced search feature** to our platform. Users are struggling to find relevant items quickly.\n",
            "**************************************************\n",
            "VENKAT : That sounds interesting. Britney, do you have any specific filters in mind? Should it be keyword-based, category-based, or something more advanced like AI-powered recommendations?\n",
            "**************************************************\n",
            "BRITNEY : A combination of both! Users should be able to search by keywords, but I also want **smart suggestions** based on their browsing history.\n",
            "**************************************************\n",
            "JOHN : From a testing perspective, we need to ensure the search results are accurate. Venkat, how complex will the AI recommendations be? We might need test cases for various user behaviors.\n",
            "**************************************************\n",
            "DEEPAK :  Agreed, John. I'm thinking we can implement a hybrid approach with natural language processing (NLP) for keyword-based searches and collaborative filtering for the AI-powered recommendations. To mitigate potential biases, we'll use a combination of techniques, such as entity disambiguation and contextual understanding. I'll start designing the architecture and we can discuss test cases in more detail later.\n",
            "**************************************************\n",
            "VENKAT :  That sounds like a good approach, Deepak. From a technical standpoint, I'll need to ensure that the NLP and collaborative filtering algorithms are properly integrated and scalable. I'll also want to discuss the data storage and retrieval requirements for the search results. We'll need to consider data types, indexing, and query optimization to ensure fast and accurate results.\n",
            "**************************************************\n",
            "JOHN :  I'll start working on test cases for the search functionality, focusing on edge cases like typos, misspellings, and ambiguous keywords. I'll also want to test the filtering and recommendation algorithms with different user profiles and browsing histories to ensure accuracy and relevance. Can we also discuss the user interface and user experience aspects of the advanced search feature?\n",
            "**************************************************\n",
            "BRITNEY :  Absolutely, John. I'd like to see a design concept for the search bar and results page that's clean and intuitive. We want to make sure users can easily understand what they're searching for and that the results are presented in a clear and organized way. Can we also discuss incorporating visual aids like faceted filtering and sorting options to help users narrow down their search results?\n",
            "**************************************************\n"
          ]
        }
      ],
      "source": [
        "for m in llama_messages:\n",
        "    print(m.get('role').upper(), \":\", m.get('content'))\n",
        "    print('*'*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngk8jCNH-1Z9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00bf846a09984d0c92e6653725b5c40c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0291cb241e7a421f84bd335d5b975a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b202f2bd609408bacc8ae0f1cabc411": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d9d85f1deb94c368fec9ef1524ef009": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "214bf9babf3a4130b23d461eb35afa63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00bf846a09984d0c92e6653725b5c40c",
            "placeholder": "​",
            "style": "IPY_MODEL_81c3d71957124c149390701970f4c594",
            "value": " 2/2 [00:00&lt;00:00,  2.16it/s]"
          }
        },
        "2802d92d8e1e44d1ab95b126758ac827": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d03c13c4e9a4dbc8b6ab2ead8662e0d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b202f2bd609408bacc8ae0f1cabc411",
            "value": 2
          }
        },
        "29f5a35630d64af0a3a934533fe79b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95117c6c1e7d4721b41c06156d098dcc",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_918c267f7f1f4aedad5996a925563459",
            "value": 2
          }
        },
        "3d011f2d51f749a19b2f2f072d85ceab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c445cfa1334e42029116f7c18daef735",
            "placeholder": "​",
            "style": "IPY_MODEL_0291cb241e7a421f84bd335d5b975a2f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "42e5a83254d549c18edc332281c57954": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d03c13c4e9a4dbc8b6ab2ead8662e0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f321409dfe24d2b94ac112baf6eeb3d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51a5be8655f44a33b8b68a34da7772b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ce3bbb7d85545a68a9d694c11c94b82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e234518ed9bf4ba49dc3169fb27624a7",
              "IPY_MODEL_29f5a35630d64af0a3a934533fe79b03",
              "IPY_MODEL_214bf9babf3a4130b23d461eb35afa63"
            ],
            "layout": "IPY_MODEL_b7bf481c0e2e49bab2cdc80e455e1c0a"
          }
        },
        "7e14e588d09741a0bad2789a433505a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1f6705fb4da468cae2357bdc7a5e930",
            "placeholder": "​",
            "style": "IPY_MODEL_8dae156c0ba34e61bf1d71668a503096",
            "value": " 2/2 [00:02&lt;00:00,  1.38s/it]"
          }
        },
        "802af72d78994207a97af0e393a3d446": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8168afcee2554b9a9e60f3a5bc6e291e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81c3d71957124c149390701970f4c594": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d67eaf860d5475180e8ca60781f574c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dae156c0ba34e61bf1d71668a503096": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "918c267f7f1f4aedad5996a925563459": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9393c2259ea24da3a65a539b023b3a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42e5a83254d549c18edc332281c57954",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_edfccbc47fe048f0a2fb9009bdd63a2a",
            "value": 2
          }
        },
        "95117c6c1e7d4721b41c06156d098dcc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96c5cd4030274b81930c500c27356c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f321409dfe24d2b94ac112baf6eeb3d",
            "placeholder": "​",
            "style": "IPY_MODEL_8168afcee2554b9a9e60f3a5bc6e291e",
            "value": " 2/2 [00:02&lt;00:00,  1.22s/it]"
          }
        },
        "97f23781c1154c709350dbb797ce8cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9aa52be74404473bd105bf553877f3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7bf481c0e2e49bab2cdc80e455e1c0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3b20d4b71284906bfdd4a21dd991769": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce2792c815de4df88e486d31331b8116",
              "IPY_MODEL_2802d92d8e1e44d1ab95b126758ac827",
              "IPY_MODEL_96c5cd4030274b81930c500c27356c6f"
            ],
            "layout": "IPY_MODEL_e4c3f90077164f70bb343e7ad58b993c"
          }
        },
        "c445cfa1334e42029116f7c18daef735": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c606c455d71a4da7b9cfe28168d3397b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdb9766def414574aba465bc71595f59",
              "IPY_MODEL_dd0f11f80494429c977e425ec2fb4f04",
              "IPY_MODEL_dcfcacbe35484acab7a62324f22b1021"
            ],
            "layout": "IPY_MODEL_cc4d61137003488a8ed8c9f5d0845e41"
          }
        },
        "c85eee084c664c079defed4545ca6305": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9437f91800b4b36a419aebc22fff2fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc4d61137003488a8ed8c9f5d0845e41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdb9766def414574aba465bc71595f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3678730711a47968e9fb67e103dcc1e",
            "placeholder": "​",
            "style": "IPY_MODEL_97f23781c1154c709350dbb797ce8cb9",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ce2792c815de4df88e486d31331b8116": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c85eee084c664c079defed4545ca6305",
            "placeholder": "​",
            "style": "IPY_MODEL_c9437f91800b4b36a419aebc22fff2fa",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "dcfcacbe35484acab7a62324f22b1021": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d67eaf860d5475180e8ca60781f574c",
            "placeholder": "​",
            "style": "IPY_MODEL_e4d27c9c1b5e4b5b95435ec96a54c44a",
            "value": " 2/2 [00:01&lt;00:00,  1.35it/s]"
          }
        },
        "dd0f11f80494429c977e425ec2fb4f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d9d85f1deb94c368fec9ef1524ef009",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51a5be8655f44a33b8b68a34da7772b0",
            "value": 2
          }
        },
        "e234518ed9bf4ba49dc3169fb27624a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9aa52be74404473bd105bf553877f3a",
            "placeholder": "​",
            "style": "IPY_MODEL_802af72d78994207a97af0e393a3d446",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e418c44ccde84a58a8da21b4b53c8eea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4c3f90077164f70bb343e7ad58b993c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4d27c9c1b5e4b5b95435ec96a54c44a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eaf9e9d9ca0642bcb807163ab479af37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d011f2d51f749a19b2f2f072d85ceab",
              "IPY_MODEL_9393c2259ea24da3a65a539b023b3a37",
              "IPY_MODEL_7e14e588d09741a0bad2789a433505a2"
            ],
            "layout": "IPY_MODEL_e418c44ccde84a58a8da21b4b53c8eea"
          }
        },
        "edfccbc47fe048f0a2fb9009bdd63a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1f6705fb4da468cae2357bdc7a5e930": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3678730711a47968e9fb67e103dcc1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
